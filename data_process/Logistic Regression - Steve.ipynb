{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('/Users/wangshuo/Downloads/AML/data/train_one_hot_100000.pkl')\n",
    "df_valid = pd.read_pickle('/Users/wangshuo/Downloads/AML/data/valid_one_hot_10000.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_label = df_train['outcome'].copy()\n",
    "df_train_input = df_train.drop(columns=['people_id','activity_id','outcome'])\n",
    "\n",
    "df_valid_label = df_valid['outcome'].copy()\n",
    "df_valid_input = df_valid.drop(columns=['people_id','activity_id','outcome'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 - Remove columns with less number of '1':  Choose 309 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns that contain less than  0.1 % of 1 are removed.\n",
      "18253 columns are removed from original 18562 columns.\n"
     ]
    }
   ],
   "source": [
    "# dimension reduction\n",
    "# the dimensions that only contain small number of '1' are dropped\n",
    "\n",
    "threshold = 0.001 # 0.1%\n",
    "\n",
    "keys = list(df_train_input)\n",
    "keys_dropped = []\n",
    "\n",
    "for key in keys:\n",
    "  tmp_sum = df_train_input[key].sum()\n",
    "  tmp_ratio = tmp_sum/len(df_train_input)\n",
    "#   print(key,tmp_ratio)\n",
    "  \n",
    "  if tmp_ratio < threshold:\n",
    "    keys_dropped.append(key)\n",
    "    \n",
    "df_train_input_reduced = df_train_input.drop(columns=keys_dropped)\n",
    "df_valid_input_reduced = df_valid_input.drop(columns=keys_dropped)\n",
    "\n",
    "print('The columns that contain less than ' , threshold*100 ,'% of 1 are removed.')\n",
    "print(len(keys_dropped),'columns are removed from original',len(keys),'columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  For Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 30 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangshuo/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   30.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='sag', tol=0.0001,\n",
       "          verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = LogisticRegression(random_state=0, solver='sag',verbose=True)\n",
    "model.fit(np.array(df_train_input_reduced.values),np.array(df_train_label.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score for Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score is  0.86507\n",
      "valid score is  0.8678\n"
     ]
    }
   ],
   "source": [
    "train_predict = model.predict(np.array(df_train_input_reduced.values))\n",
    "train_score = accuracy_score(train_predict,np.array(df_train_label.values))\n",
    "print('train score is ',train_score)\n",
    "\n",
    "valid_predict = model.predict(np.array(df_valid_input_reduced.values))\n",
    "valid_score = accuracy_score(valid_predict,np.array(df_valid_label.values))\n",
    "print('valid score is ',valid_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 - PCA: Choose 300 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "estimator = PCA(n_components = 300)\n",
    "\n",
    "pca_df_train_input = estimator.fit_transform(df_train_input)\n",
    "pca_df_valid_input = estimator.transform(df_valid_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_df_train_input.shape\n",
    "# pca_df_valid_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  For Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 28 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangshuo/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   28.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='sag', tol=0.0001,\n",
       "          verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = LogisticRegression(random_state=0, solver='sag',verbose=True)\n",
    "model.fit(np.array(pca_df_train_input),np.array(df_train_label.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score for Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score is  0.8656\n",
      "valid score is  0.8677\n"
     ]
    }
   ],
   "source": [
    "train_predict = model.predict(np.array(pca_df_train_input))\n",
    "train_score = accuracy_score(train_predict,np.array(df_train_label.values))\n",
    "print('train score is ',train_score)\n",
    "\n",
    "valid_predict = model.predict(np.array(pca_df_valid_input))\n",
    "valid_score = accuracy_score(valid_predict,np.array(df_valid_label.values))\n",
    "print('valid score is ',valid_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
